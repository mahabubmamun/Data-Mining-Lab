{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b799c2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed1c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "ucirepo_ids = {\n",
    "    \"iris\": 53,\n",
    "    \"mushroom\": 73,\n",
    "    \"car_eval\": 19, \n",
    "}\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "def custom_data():\n",
    "    \n",
    "    data = {\n",
    "            'age': ['youth', 'youth', 'middle aged', 'senior', 'senior', 'senior', 'middle aged',\n",
    "                    'youth', 'youth', 'senior', 'youth', 'middle aged', 'middle aged', 'senior'],\n",
    "            'income': ['high', 'high', 'high', 'medium', 'low', 'low', 'low',\n",
    "                    'medium', 'low', 'medium', 'medium', 'medium', 'high', 'medium'],\n",
    "            'student': ['no', 'no', 'no', 'no', 'yes', 'yes', 'yes',\n",
    "                        'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no'],\n",
    "            'credit_rating': ['fair', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent',\n",
    "                            'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'excellent'],\n",
    "            'buys_computer': ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes',\n",
    "                            'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n",
    "        }\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Split into features and target\n",
    "    features = df.drop(columns='buys_computer')\n",
    "    targets = df['buys_computer']\n",
    "    targets= pd.DataFrame(targets.values.reshape(-1, 1), columns=['buys_computer'])\n",
    "\n",
    "    \n",
    "    # Variable info\n",
    "    variable_info = {\n",
    "        col: {\n",
    "            'type': 'categorical',\n",
    "            'unique_values': df[col].unique().tolist()\n",
    "        } for col in df.columns\n",
    "    }\n",
    "\n",
    "    # Metadata\n",
    "    metadata = {\n",
    "        'source': 'Simulated AllElectronics dataset',\n",
    "        'description': 'Customer attributes and their decision to buy a computer',\n",
    "        'num_samples': len(df),\n",
    "        'num_features': features.shape[1],\n",
    "        'target_column': 'buys_computer',\n",
    "        'class_labels': sorted(df['buys_computer'].unique().tolist())\n",
    "    }\n",
    "\n",
    "    # Build nested structure\n",
    "    return SimpleNamespace(\n",
    "        data=SimpleNamespace(\n",
    "            features=features,\n",
    "            targets=targets,\n",
    "            feature_names=features.columns.tolist(),\n",
    "            target_names=sorted(targets.iloc[:,0].unique()),\n",
    "            # frame=df\n",
    "        ),\n",
    "        metadata=metadata,\n",
    "        variables=variable_info\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "def fetch_dataframe(dataframe_name):\n",
    "    \n",
    "    if dataframe_name == \"custom_data\":\n",
    "        df = custom_data()\n",
    "        \n",
    "        # metadata \n",
    "        print(df.metadata) \n",
    "        \n",
    "        # variable information \n",
    "        print(df.variables) \n",
    "    \n",
    "        return df\n",
    "    \n",
    "    if dataframe_name in ucirepo_ids:\n",
    "        # fetch dataset \n",
    "        df = fetch_ucirepo(id=ucirepo_ids[dataframe_name],) \n",
    "\n",
    "        # # data (as pandas dataframes) \n",
    "        X = df.data.features \n",
    "        y = df.data.targets \n",
    "        \n",
    "        # metadata \n",
    "        print(df.metadata) \n",
    "        \n",
    "        # variable information \n",
    "        print(df.variables) \n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset '{dataframe_name}' not found in UCI repository.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b066afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __train_test_split(X, y, test_size = 0.2, shuffle_and_stratify = True):\n",
    "    \n",
    "    if test_size < 0 or test_size > 1:\n",
    "        raise ValueError(\"test_size must be between 0 and 1\")\n",
    "   \n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(\"Features and targets must have the same length.\")\n",
    "\n",
    "    \n",
    "    if shuffle_and_stratify == False:\n",
    "    \n",
    "        train_size = 1 - test_size\n",
    "        train_index = int(len(X) * train_size)\n",
    "        \n",
    "        X_train = X[0: train_index]\n",
    "        X_test = X[train_index:]\n",
    "        \n",
    "        y_train = y[0: train_index]\n",
    "        y_test = y[train_index:]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    else:\n",
    "        labels = y.iloc[:,0].unique()\n",
    "        X_train = pd.DataFrame(columns=X.columns)\n",
    "        y_train = pd.DataFrame(columns=y.columns)\n",
    "        X_test = pd.DataFrame(columns=X.columns)\n",
    "        y_test = pd.DataFrame(columns=y.columns)\n",
    "        \n",
    "        train_size = 1 - test_size\n",
    "        \n",
    "\n",
    "        for label in labels :\n",
    "            y_rows = y[y.iloc[:,0] == label]            \n",
    "            X_rows = X.loc[y_rows.index]\n",
    "            \n",
    "            train_index = int(len(X_rows) * train_size)\n",
    "            \n",
    "            X_train = pd.concat([X_train, X_rows.iloc[:train_index]], ignore_index=False)\n",
    "            y_train = pd.concat([y_train, y_rows.iloc[:train_index]] , ignore_index=False)\n",
    "            \n",
    "            X_test = pd.concat([X_test, X_rows[train_index:]], ignore_index=False)\n",
    "            y_test = pd.concat([y_test, y_rows[train_index:]], ignore_index=False)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77bcfedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 19, 'name': 'Car Evaluation', 'repository_url': 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'data_url': 'https://archive.ics.uci.edu/static/public/19/data.csv', 'abstract': 'Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.', 'area': 'Other', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 1728, 'num_features': 6, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1988, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5JP48', 'creators': ['Marko Bohanec'], 'intro_paper': {'ID': 249, 'type': 'NATIVE', 'title': 'Knowledge acquisition and explanation for multi-attribute decision making', 'authors': 'M. Bohanec, V. Rajkoviƒç', 'venue': '8th Intl Workshop on Expert Systems and their Applications, Avignon, France', 'year': 1988, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/KNOWLEDGE-ACQUISITION-AND-EXPLANATION-FOR-DECISION-Bohanec-Rajkovi%C4%8D/8bab443ae322ff47c3e609272bd93fd4650555bc', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure:\\r\\n\\r\\nCAR                      car acceptability\\r\\n. PRICE                  overall price\\r\\n. . buying               buying price\\r\\n. . maint                price of the maintenance\\r\\n. TECH                   technical characteristics\\r\\n. . COMFORT              comfort\\r\\n. . . doors              number of doors\\r\\n. . . persons            capacity in terms of persons to carry\\r\\n. . . lug_boot           the size of luggage boot\\r\\n. . safety               estimated safety of the car\\r\\n\\r\\nInput attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\\r\\n\\r\\nThe Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety.\\r\\n\\r\\nBecause of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'buying:   vhigh, high, med, low.\\nmaint:    vhigh, high, med, low.\\ndoors:    2, 3, 4, 5more.\\npersons:  2, 4, more.\\nlug_boot: small, med, big.\\nsafety:   low, med, high.', 'citation': None}}\n",
      "       name     role         type demographic  \\\n",
      "0    buying  Feature  Categorical        None   \n",
      "1     maint  Feature  Categorical        None   \n",
      "2     doors  Feature  Categorical        None   \n",
      "3   persons  Feature  Categorical        None   \n",
      "4  lug_boot  Feature  Categorical        None   \n",
      "5    safety  Feature  Categorical        None   \n",
      "6     class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                       buying price  None             no  \n",
      "1                           price of the maintenance  None             no  \n",
      "2                                    number of doors  None             no  \n",
      "3              capacity in terms of persons to carry  None             no  \n",
      "4                           the size of luggage boot  None             no  \n",
      "5                        estimated safety of the car  None             no  \n",
      "6  evaulation level (unacceptable, acceptable, go...  None             no  \n",
      "<built-in method values of dotdict object at 0x00000171FFD66EE0>\n"
     ]
    }
   ],
   "source": [
    "df = fetch_dataframe(\"car_eval\")\n",
    "\n",
    "print(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c421e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1382, 6)\n",
      "X_test shape: (346, 6)\n",
      "y_train shape: (1382, 1)\n",
      "y_test shape: (346, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.data.features\n",
    "y = df.data.targets\n",
    "\n",
    "X_train, X_test, y_train, y_test = __train_test_split(X, y , test_size=TEST_SIZE, shuffle_and_stratify=True)\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE)\n",
    "\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9e595ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1382 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     buying  maint doors persons lug_boot safety\n",
       "0     vhigh  vhigh     2       2    small    low\n",
       "1     vhigh  vhigh     2       2    small    med\n",
       "2     vhigh  vhigh     2       2    small   high\n",
       "3     vhigh  vhigh     2       2      med    low\n",
       "4     vhigh  vhigh     2       2      med    med\n",
       "...     ...    ...   ...     ...      ...    ...\n",
       "1645    low    low     2    more      big    med\n",
       "1658    low    low     3       4    small   high\n",
       "1661    low    low     3       4      med   high\n",
       "1663    low    low     3       4      big    med\n",
       "1667    low    low     3    more    small   high\n",
       "\n",
       "[1382 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33e98417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1382 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class\n",
       "0     unacc\n",
       "1     unacc\n",
       "2     unacc\n",
       "3     unacc\n",
       "4     unacc\n",
       "...     ...\n",
       "1645   good\n",
       "1658   good\n",
       "1661   good\n",
       "1663   good\n",
       "1667   good\n",
       "\n",
       "[1382 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2137948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = y_train.iloc[:,0].unique()\n",
    "\n",
    "# for label in labels:\n",
    "    \n",
    "#     label_rows = y_train[y_train.iloc[:,0] == label]\n",
    "    \n",
    "#     row_indices = label_rows.index\n",
    "    \n",
    "#     print(row_indices)\n",
    "    \n",
    "#     corresponding_rows = X_train.loc[label_rows.index]\n",
    "    \n",
    "#     for ind in row_indices:\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if ind not in X_train.index:\n",
    "#             print(f\"{ind} not in X_train for label {label}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4ea5041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes: Index(['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'], dtype='object')\n",
      "Class Labels: ['unacc' 'acc' 'vgood' 'good']\n",
      "Predictions Length: 346\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from math import exp, sqrt, pi\n",
    "    \n",
    "def gaussian(x_k, mean, std):\n",
    "    \n",
    "    if std == 0:\n",
    "        return 1 if x_k == mean else 0\n",
    "    else:\n",
    "        exponent = exp(-((x_k - mean)**2 ) / (2*std**2))\n",
    "        gaussian_val = (1 / (sqrt(2*pi*std**2))) * exponent\n",
    "        return gaussian_val\n",
    "\n",
    "def naive_bayes_classifier_preds(X_train,y_train, X_test):\n",
    "    y_preds = []\n",
    "    attributes = X_train.columns\n",
    "    labels = y_train.iloc[:,0].unique()\n",
    "    \n",
    "    print(\"Attributes:\", attributes)\n",
    "    print(\"Class Labels:\", labels)\n",
    "    \n",
    "    # print(\"y_train:\\n\", y_train)\n",
    "    \n",
    "    label_probs = {}\n",
    "    cond_probs = {}\n",
    "    mean_store = {}\n",
    "    std_store = {}\n",
    "    \n",
    "    \n",
    "    for label in labels:\n",
    "        label_probs[label] = (y_train.iloc[:,0] == label).sum() / len(y_train) # Calculate prior probabilities for each label\n",
    "        \n",
    "        label_rows = y_train[y_train.iloc[:,0] == label]\n",
    "        \n",
    "        # print(f\"Label: {label}, Probability: {label_probs[label]} count: {(y_train.iloc[:,0] == label).sum() }\")\n",
    "        # print(\"Label Rows: \\n\", label_rows)\n",
    "        \n",
    "        for attr in attributes:\n",
    "            if type(X_train[attr].iloc[0]) == str: #categotrical attribute\n",
    "                corresponding_rows = X_train.loc[label_rows.index]\n",
    "                attr_value_counts = corresponding_rows[attr].value_counts().to_dict()\n",
    "                \n",
    "                for attr_value, count in attr_value_counts.items():\n",
    "                    cond_probs[(attr, attr_value, label)] = count / len(corresponding_rows)\n",
    "            elif type(X_train[attr].iloc[0]) == float or type(X_train[attr].iloc[0]) == int: # numerical attribute\n",
    "                corresponding_rows = X_train.loc[label_rows.index]\n",
    "                mean = corresponding_rows[attr].mean()\n",
    "                std = corresponding_rows[attr].std()\n",
    "                \n",
    "                mean_store[(attr, label)] = mean\n",
    "                std_store[(attr, label)] = std\n",
    "                \n",
    "                \n",
    "    # print(\"Label Probabilities:\", label_probs)\n",
    "    # print(\"Conditional Probabilities:\", cond_probs)\n",
    "    \n",
    "    # for key, value in cond_probs.items():\n",
    "    #     print(f\"Conditional Probability {key}: {value}\")\n",
    "    \n",
    "    # Create one test row\n",
    "    # test_data = {\n",
    "    #     \"age\":   [\"youth\"],\n",
    "    #     \"income\":    [\"medium\"],\n",
    "    #     \"student\":    [\"yes\"],\n",
    "    #     \"credit_rating\":  [\"fair\"],\n",
    "    # }\n",
    "\n",
    "    # test_df = pd.DataFrame(test_data)\n",
    "\n",
    "    # print(test_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for index, test_row in X_test.iterrows():\n",
    "        \n",
    "        prob_max_finder = {}\n",
    "        \n",
    "        for label in labels:\n",
    "            prob = label_probs[label]\n",
    "            \n",
    "            for attr in attributes:\n",
    "                \n",
    "                attr_value = test_row[attr]\n",
    "                \n",
    "                if type(attr_value) == str:\n",
    "            \n",
    "                    prob *= cond_probs.get((attr, attr_value , label), 1e-6) \n",
    "                \n",
    "                elif type(attr_value) == float or type(attr_value) == int:\n",
    "                    \n",
    "                    mean = mean_store[(attr, label)]\n",
    "                    std = std_store[(attr, label)] + 1e-7\n",
    "                    \n",
    "                    prob *= gaussian(x_k=attr_value, mean=mean, std=std) \n",
    "            \n",
    "            prob_max_finder[label] = prob\n",
    "            \n",
    "            \n",
    "        max_label = max(prob_max_finder, key=prob_max_finder.get)\n",
    "        \n",
    "        y_preds.append(max_label)\n",
    "    \n",
    "            \n",
    "    \n",
    "    # print(\"Predictions:\", y_preds)\n",
    "    print(\"Predictions Length:\", len(y_preds))\n",
    "    \n",
    "    return y_preds\n",
    "    \n",
    "\n",
    "y_preds = naive_bayes_classifier_preds(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c871b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __classification_report(y_true, y_pred):\n",
    "    \n",
    "    if len(y_true.iloc[:,0]) != len(y_pred):\n",
    "        raise NotImplementedError(\"prediction does not have same number of tuples as the true value set\")\n",
    "    \n",
    "    labels = y_true.iloc[:, 0].unique()\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for label in labels:\n",
    "        P = N = TP = FP = TN = FN = 0\n",
    "        \n",
    "        for i in range(len(y_pred)):\n",
    "            true_label = y_true.iloc[i,0]\n",
    "            pred_label = y_pred[i]\n",
    "            \n",
    "            if true_label == label:\n",
    "                P += 1\n",
    "            else:\n",
    "                N += 1\n",
    "                \n",
    "            if true_label==label and pred_label==label:\n",
    "                TP += 1\n",
    "            elif true_label==label and pred_label!=label:\n",
    "                FN += 1\n",
    "            elif true_label!=label and pred_label==label:\n",
    "                FP += 1\n",
    "            elif true_label!=label and pred_label!=label:\n",
    "                TN += 1\n",
    "                \n",
    "            \n",
    "            accuracy = (TP+TN) / (P+N)\n",
    "            precision = TP / (TP + FP)\n",
    "            recall = TP / (TP + FN)\n",
    "            f1_score = (2 * precision * recall) / (precision + recall)\n",
    "            sensitivity = TP/P\n",
    "            specificity = TN/N            \n",
    "            support = P + N\n",
    "            \n",
    "            ################# what if P,N either or both 0 ????\n",
    "            \n",
    "            print(f\"Label: {label}\")\n",
    "            print(f\"  Accuracy   : {accuracy:.2f}\")\n",
    "            print(f\"  Precision  : {precision:.2f}\")\n",
    "            print(f\"  Recall     : {recall:.2f}\")\n",
    "            print(f\"  F1 Score   : {f1_score:.2f}\")\n",
    "            print(f\"  Sensitivity: {sensitivity:.2f}\")\n",
    "            print(f\"  Specificity: {specificity:.2f}\")\n",
    "            print(f\"  Support    : {support}\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "# __classification_report(y_true=y_test, y_pred = y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0335ca1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.96      0.69      0.80        77\n",
      "        good       0.32      1.00      0.48        14\n",
      "       unacc       1.00      0.98      0.99       242\n",
      "       vgood       0.70      0.54      0.61        13\n",
      "\n",
      "    accuracy                           0.90       346\n",
      "   macro avg       0.74      0.80      0.72       346\n",
      "weighted avg       0.95      0.90      0.91       346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_preds)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20b59076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_encoded [[3. 3. 0. 0. 2. 1.]\n",
      " [3. 3. 0. 0. 2. 2.]\n",
      " [3. 3. 0. 0. 2. 0.]\n",
      " ...\n",
      " [1. 1. 3. 2. 0. 1.]\n",
      " [1. 1. 3. 2. 0. 2.]\n",
      " [1. 1. 3. 2. 0. 0.]]\n",
      "X_train [[3. 3. 3. 2. 0. 0.]\n",
      " [2. 3. 1. 1. 2. 2.]\n",
      " [1. 1. 3. 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 3. 2. 1. 0.]\n",
      " [1. 0. 2. 0. 2. 2.]\n",
      " [2. 2. 1. 2. 2. 2.]]\n",
      "Classification Report (sklearn):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         acc       0.63      0.54      0.58        83\n",
      "        good       0.57      0.36      0.44        11\n",
      "       unacc       0.87      0.97      0.91       235\n",
      "       vgood       1.00      0.35      0.52        17\n",
      "\n",
      "    accuracy                           0.82       346\n",
      "   macro avg       0.77      0.56      0.62       346\n",
      "weighted avg       0.81      0.82      0.80       346\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "X_sk = df.data.features\n",
    "y_sk = df.data.targets\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "X_encoded = encoder.fit_transform(X_sk)\n",
    "\n",
    "print(f\"X_encoded {X_encoded}\")\n",
    "\n",
    "X_train_sk, X_test_sk, y_train_sk, y_test_sk = train_test_split(X_encoded, y_sk , test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train\", X_train_sk)\n",
    "\n",
    "model = CategoricalNB()  # Use CategoricalNB for categorical data\n",
    "# model = GaussianNB()  # Use GaussianNB for numerical data\n",
    "\n",
    "model.fit(X_train_sk, y_train_sk)\n",
    "\n",
    "y_preds_sklearn = model.predict(X_test_sk)\n",
    "\n",
    "report_sklearn = classification_report(y_test_sk, y_preds_sklearn)\n",
    "\n",
    "print(\"Classification Report (sklearn):\")\n",
    "print(report_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d9de785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Predictions:\n",
      "Sample 1: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 2: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 3: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 4: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 5: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 6: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 7: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 8: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 9: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 10: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 11: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 12: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 13: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 14: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 15: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 16: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 17: Actual: unacc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 18: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 19: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 20: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 21: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 22: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 23: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 24: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 25: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 26: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 27: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 28: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 29: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 30: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 31: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 32: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 33: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 34: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 35: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 36: Actual: unacc, Naive Bayes: unacc, sklearn: good\n",
      "Sample 37: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 38: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 39: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 40: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 41: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 42: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 43: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 44: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 45: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 46: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 47: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 48: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 49: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 50: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 51: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 52: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 53: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 54: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 55: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 56: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 57: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 58: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 59: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 60: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 61: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 62: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 63: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 64: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 65: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 66: Actual: unacc, Naive Bayes: unacc, sklearn: vgood\n",
      "Sample 67: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 68: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 69: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 70: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 71: Actual: unacc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 72: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 73: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 74: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 75: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 76: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 77: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 78: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 79: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 80: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 81: Actual: unacc, Naive Bayes: unacc, sklearn: vgood\n",
      "Sample 82: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 83: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 84: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 85: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 86: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 87: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 88: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 89: Actual: unacc, Naive Bayes: unacc, sklearn: vgood\n",
      "Sample 90: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 91: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 92: Actual: unacc, Naive Bayes: unacc, sklearn: good\n",
      "Sample 93: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 94: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 95: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 96: Actual: unacc, Naive Bayes: unacc, sklearn: good\n",
      "Sample 97: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 98: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 99: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 100: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 101: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 102: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 103: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 104: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 105: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 106: Actual: unacc, Naive Bayes: unacc, sklearn: good\n",
      "Sample 107: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 108: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 109: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 110: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 111: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 112: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 113: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 114: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 115: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 116: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 117: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 118: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 119: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 120: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 121: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 122: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 123: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 124: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 125: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 126: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 127: Actual: unacc, Naive Bayes: unacc, sklearn: good\n",
      "Sample 128: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 129: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 130: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 131: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 132: Actual: unacc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 133: Actual: unacc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 134: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 135: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 136: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 137: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 138: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 139: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 140: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 141: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 142: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 143: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 144: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 145: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 146: Actual: unacc, Naive Bayes: unacc, sklearn: good\n",
      "Sample 147: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 148: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 149: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 150: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 151: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 152: Actual: unacc, Naive Bayes: unacc, sklearn: vgood\n",
      "Sample 153: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 154: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 155: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 156: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 157: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 158: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 159: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 160: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 161: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 162: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 163: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 164: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 165: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 166: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 167: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 168: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 169: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 170: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 171: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 172: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 173: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 174: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 175: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 176: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 177: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 178: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 179: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 180: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 181: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 182: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 183: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 184: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 185: Actual: unacc, Naive Bayes: unacc, sklearn: good\n",
      "Sample 186: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 187: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 188: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 189: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 190: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 191: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 192: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 193: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 194: Actual: unacc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 195: Actual: unacc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 196: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 197: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 198: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 199: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 200: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 201: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 202: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 203: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 204: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 205: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 206: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 207: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 208: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 209: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 210: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 211: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 212: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 213: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 214: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 215: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 216: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 217: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 218: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 219: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 220: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 221: Actual: unacc, Naive Bayes: unacc, sklearn: vgood\n",
      "Sample 222: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 223: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 224: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 225: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 226: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 227: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 228: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 229: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 230: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 231: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 232: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 233: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 234: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 235: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 236: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 237: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 238: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 239: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 240: Actual: unacc, Naive Bayes: unacc, sklearn: acc\n",
      "Sample 241: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 242: Actual: unacc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 243: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 244: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 245: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 246: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 247: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 248: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 249: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 250: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 251: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 252: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 253: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 254: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 255: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 256: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 257: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 258: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 259: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 260: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 261: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 262: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 263: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 264: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 265: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 266: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 267: Actual: acc, Naive Bayes: unacc, sklearn: unacc\n",
      "Sample 268: Actual: acc, Naive Bayes: acc, sklearn: vgood\n",
      "Sample 269: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 270: Actual: acc, Naive Bayes: vgood, sklearn: unacc\n",
      "Sample 271: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 272: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 273: Actual: acc, Naive Bayes: vgood, sklearn: unacc\n",
      "Sample 274: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 275: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 276: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 277: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 278: Actual: acc, Naive Bayes: vgood, sklearn: unacc\n",
      "Sample 279: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 280: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 281: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 282: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 283: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 284: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 285: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 286: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 287: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 288: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 289: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 290: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 291: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 292: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 293: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 294: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 295: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 296: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 297: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 298: Actual: acc, Naive Bayes: acc, sklearn: acc\n",
      "Sample 299: Actual: acc, Naive Bayes: acc, sklearn: unacc\n",
      "Sample 300: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 301: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 302: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 303: Actual: acc, Naive Bayes: good, sklearn: acc\n",
      "Sample 304: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 305: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 306: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 307: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 308: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 309: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 310: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 311: Actual: acc, Naive Bayes: good, sklearn: acc\n",
      "Sample 312: Actual: acc, Naive Bayes: good, sklearn: acc\n",
      "Sample 313: Actual: acc, Naive Bayes: good, sklearn: acc\n",
      "Sample 314: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 315: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 316: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 317: Actual: acc, Naive Bayes: good, sklearn: acc\n",
      "Sample 318: Actual: acc, Naive Bayes: good, sklearn: acc\n",
      "Sample 319: Actual: acc, Naive Bayes: good, sklearn: unacc\n",
      "Sample 320: Actual: vgood, Naive Bayes: good, sklearn: acc\n",
      "Sample 321: Actual: vgood, Naive Bayes: good, sklearn: unacc\n",
      "Sample 322: Actual: vgood, Naive Bayes: good, sklearn: unacc\n",
      "Sample 323: Actual: vgood, Naive Bayes: good, sklearn: unacc\n",
      "Sample 324: Actual: vgood, Naive Bayes: vgood, sklearn: unacc\n",
      "Sample 325: Actual: vgood, Naive Bayes: good, sklearn: unacc\n",
      "Sample 326: Actual: vgood, Naive Bayes: vgood, sklearn: unacc\n",
      "Sample 327: Actual: vgood, Naive Bayes: vgood, sklearn: unacc\n",
      "Sample 328: Actual: vgood, Naive Bayes: vgood, sklearn: acc\n",
      "Sample 329: Actual: vgood, Naive Bayes: good, sklearn: unacc\n",
      "Sample 330: Actual: vgood, Naive Bayes: vgood, sklearn: unacc\n",
      "Sample 331: Actual: vgood, Naive Bayes: vgood, sklearn: unacc\n",
      "Sample 332: Actual: vgood, Naive Bayes: vgood, sklearn: unacc\n",
      "Sample 333: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 334: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 335: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 336: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 337: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 338: Actual: good, Naive Bayes: good, sklearn: acc\n",
      "Sample 339: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 340: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 341: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 342: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 343: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 344: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 345: Actual: good, Naive Bayes: good, sklearn: unacc\n",
      "Sample 346: Actual: good, Naive Bayes: good, sklearn: unacc\n"
     ]
    }
   ],
   "source": [
    "ys = [[y_test.iloc[i,0], y_preds[i], y_preds_sklearn[i]] for i in range(len(y_test))]\n",
    "\n",
    "print(\"Comparison of Predictions:\")\n",
    "for i, (actual, naive_bayes_pred, sklearn_pred) in enumerate(ys):\n",
    "    print(f\"Sample {i+1}: Actual: {actual}, Naive Bayes: {naive_bayes_pred}, sklearn: {sklearn_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b9a5b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "train_test_split(\n",
      "    *arrays,\n",
      "    test_size=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    train_size=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    random_state=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    stratify=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      ")\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Split arrays or matrices into random train and test subsets.\n",
      "\n",
      "Quick utility that wraps input validation,\n",
      "``next(ShuffleSplit().split(X, y))``, and application to input data\n",
      "into a single call for splitting (and optionally subsampling) data into a\n",
      "one-liner.\n",
      "\n",
      "Read more in the :ref:`User Guide <cross_validation>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "*arrays : sequence of indexables with same length / shape[0]\n",
      "    Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "    matrices or pandas dataframes.\n",
      "\n",
      "test_size : float or int, default=None\n",
      "    If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "    of the dataset to include in the test split. If int, represents the\n",
      "    absolute number of test samples. If None, the value is set to the\n",
      "    complement of the train size. If ``train_size`` is also None, it will\n",
      "    be set to 0.25.\n",
      "\n",
      "train_size : float or int, default=None\n",
      "    If float, should be between 0.0 and 1.0 and represent the\n",
      "    proportion of the dataset to include in the train split. If\n",
      "    int, represents the absolute number of train samples. If None,\n",
      "    the value is automatically set to the complement of the test size.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Controls the shuffling applied to the data before applying the split.\n",
      "    Pass an int for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "shuffle : bool, default=True\n",
      "    Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "    then stratify must be None.\n",
      "\n",
      "stratify : array-like, default=None\n",
      "    If not None, data is split in a stratified fashion, using this as\n",
      "    the class labels.\n",
      "    Read more in the :ref:`User Guide <stratification>`.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "splitting : list, length=2 * len(arrays)\n",
      "    List containing train-test split of inputs.\n",
      "\n",
      "    .. versionadded:: 0.16\n",
      "        If the input is sparse, the output will be a\n",
      "        ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "        input type.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from sklearn.model_selection import train_test_split\n",
      ">>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      ">>> X\n",
      "array([[0, 1],\n",
      "       [2, 3],\n",
      "       [4, 5],\n",
      "       [6, 7],\n",
      "       [8, 9]])\n",
      ">>> list(y)\n",
      "[0, 1, 2, 3, 4]\n",
      "\n",
      ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "...     X, y, test_size=0.33, random_state=42)\n",
      "...\n",
      ">>> X_train\n",
      "array([[4, 5],\n",
      "       [0, 1],\n",
      "       [6, 7]])\n",
      ">>> y_train\n",
      "[2, 0, 3]\n",
      ">>> X_test\n",
      "array([[2, 3],\n",
      "       [8, 9]])\n",
      ">>> y_test\n",
      "[1, 4]\n",
      "\n",
      ">>> train_test_split(y, shuffle=False)\n",
      "[[0, 1, 2], [3, 4]]\n",
      "\n",
      ">>> from sklearn import datasets\n",
      ">>> iris = datasets.load_iris(as_frame=True)\n",
      ">>> X, y = iris['data'], iris['target']\n",
      ">>> X.head()\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      ">>> y.head()\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "...\n",
      "\n",
      ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "... X, y, test_size=0.33, random_state=42)\n",
      "...\n",
      ">>> X_train.head()\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "96                 5.7               2.9                4.2               1.3\n",
      "105                7.6               3.0                6.6               2.1\n",
      "66                 5.6               3.0                4.5               1.5\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "122                7.7               2.8                6.7               2.0\n",
      ">>> y_train.head()\n",
      "96     1\n",
      "105    2\n",
      "66     1\n",
      "0      0\n",
      "122    2\n",
      "...\n",
      ">>> X_test.head()\n",
      "    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "73                 6.1               2.8                4.7               1.2\n",
      "18                 5.7               3.8                1.7               0.3\n",
      "118                7.7               2.6                6.9               2.3\n",
      "78                 6.0               2.9                4.5               1.5\n",
      "76                 6.8               2.8                4.8               1.4\n",
      ">>> y_test.head()\n",
      "73     1\n",
      "18     0\n",
      "118    2\n",
      "78     1\n",
      "76     1\n",
      "...\n",
      "\u001b[31mFile:\u001b[39m      c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\sklearn\\model_selection\\_split.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "train_test_split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df227c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72368eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3311a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
